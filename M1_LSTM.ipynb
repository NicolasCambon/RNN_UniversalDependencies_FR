{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M1_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc7DMjd1uPpB",
        "colab_type": "code",
        "outputId": "09473330-b23e-48ec-cc7f-ea2d1bf60ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://github.com/NicolasCambon/RNN_UniversalDependencies_FR.git #Téléchargment des données"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'RNN_UniversalDependencies_FR'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 34 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLxHtEhK81l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91673d24-90d9-43c2-bb2f-09adb37e6dbe"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def train(fic):\n",
        "  print(\"lecture des donnees d'entrée depuis le fichier : \", fic) \n",
        "  try:\n",
        "    fichier = open(fic,\"r\")\n",
        "  except IOError:\n",
        "    print(\"le fichier\",fic, \"n'existe pas\")\n",
        "    return None\n",
        "  \n",
        "  liste=[]\n",
        "  for ligne in fichier :  \n",
        "    ligne = ligne.strip('\\n\\r') \n",
        "    seq = [x for x in ligne.split()]  \n",
        "    liste.append(seq)  \n",
        "  fichier.close()\n",
        "  \n",
        "  sentence = []\n",
        "  part=[]\n",
        "  for l in range (len(liste)-1):\n",
        "    if len(liste[l])!= 0:\n",
        "      part.append(liste[l])\n",
        "    else:\n",
        "      sentence.append(part)\n",
        "      part=[]\n",
        "\n",
        "  POP=[]\n",
        "  Out=[]\n",
        "  for i in range(len(sentence)):  \n",
        "    pa=[]\n",
        "    no=[]\n",
        "    if i <= len(sentence)//2:\n",
        "      for e in range(2,len(sentence[i])):\n",
        "        flag=0\n",
        "        inf=''\n",
        "        nomb=''\n",
        "        if sentence[i][e][3] == \"AUX\":\n",
        "          if sentence[i][e][2] == \"avoir\":\n",
        "            inf+='_avoir'\n",
        "          else:\n",
        "            inf+='_etre'\n",
        "\n",
        "        if \"Sing\" in sentence[i][e][5]:\n",
        "          nomb+=\"_S\"\n",
        "        elif \"Plur\" in sentence[i][e][5]:\n",
        "          nomb+=\"_P\"\n",
        "        pa.append(sentence[i][e][3]+inf+nomb)\n",
        "        no.append(\"1\")\n",
        "      POP.append(pa)\n",
        "      Out.append(no)\n",
        "      \n",
        "    else:\n",
        "      for e in range(2,len(sentence[i])):\n",
        "        flag=0\n",
        "        inf=''\n",
        "        nomb=''\n",
        "        if sentence[i][e][3] == \"AUX\":\n",
        "          if sentence[i][e][2] == \"avoir\":\n",
        "            inf+='_avoir'\n",
        "          else:\n",
        "            inf+='_etre'\n",
        "            \n",
        "        if sentence[i][e][3] != \"VERB\":\n",
        "          if \"Sing\" in sentence[i][e][5]:\n",
        "            nomb+=\"_S\"\n",
        "          elif \"Plur\" in sentence[i][e][5]:\n",
        "            nomb+=\"_P\"\n",
        "          pa.append(sentence[i][e][3]+inf+nomb)\n",
        "          no.append(\"1\")\n",
        "        elif sentence[i][e][3] == \"VERB\":\n",
        "          if \"Sing\" in sentence[i][e][5]:\n",
        "            nomb+=\"_P\"\n",
        "            break\n",
        "          elif \"Plur\" in sentence[i][e][5]:\n",
        "            nomb+=\"_S\"\n",
        "            break\n",
        "          pa.append(sentence[i][e][3]+inf+nomb)\n",
        "          if len(nomb) != 0:\n",
        "            no.append(\"0\")\n",
        "          else: #elif len(nomb) == 0:\n",
        "            no.append(\"1\")\n",
        "          \n",
        "      POP.append(pa)\n",
        "      Out.append(no)\n",
        "  return(POP,Out)\n",
        "\n",
        "x_train,y_train= train('RNN_UniversalDependencies_FR/Donnees/fr_sequoia-ud-train.conllu.txt')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lecture des donnees d'entrée depuis le fichier :  RNN_UniversalDependencies_FR/Donnees/fr_sequoia-ud-train.conllu.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "its_l7Qtfz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "2db81dcb-4eff-4505-aae0-ec925ab5f142"
      },
      "source": [
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(x_train[-253])\n",
        "print(y_train[-253])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2230\n",
            "2230\n",
            "['DET_S', 'NOUN_S', 'ADP', 'NOUN_P', 'ADP', 'NOUN_S', 'AUX_avoir_P', 'AUX_etre', 'VERB', 'ADP', 'NOUN_S', 'PUNCT', 'ADV', 'SCONJ', 'DET_P', 'ADJ_P', 'NOUN_P', 'ADP', 'DET_S', 'NOUN_S', 'NOUN', 'ADP', 'DET_S', 'PROPN_S', '_', 'ADP', 'DET_S', 'NOUN_S', '_', 'ADP', 'DET_P', 'NOUN_P', 'NUM', 'PUNCT', 'CCONJ', 'ADP', '_', 'ADP', 'DET_S', 'NOUN_S', 'PROPN', 'ADP', 'DET_S', 'NOUN_S', 'ADP', 'PROPN_S', 'PUNCT', 'PROPN_S', 'PROPN', 'PUNCT', 'DET_S', 'NUM', 'NOUN_S', 'NUM', 'PUNCT']\n",
            "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NiFTb58tA58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_verbe(fic):\n",
        "  try:\n",
        "    fichier = open(fic,\"r\")\n",
        "  except IOError:\n",
        "    print(\"le fichier\",fic, \"n'existe pas\")\n",
        "    return None\n",
        "  \n",
        "  liste=[]\n",
        "  for ligne in fichier :  \n",
        "    ligne = ligne.strip('\\n\\r') \n",
        "    seq = [x for x in ligne.split()]  \n",
        "    liste.append(seq)  \n",
        "  fichier.close()\n",
        "  \n",
        "  sentence = []\n",
        "  part=[]\n",
        "  for l in range (len(liste)-1):\n",
        "    if len(liste[l])!= 0:\n",
        "      part.append(liste[l])\n",
        "    else:\n",
        "      sentence.append(part)\n",
        "      part=[]\n",
        "  num=0\n",
        "  deno=0\n",
        "  for i in range (len(sentence)):\n",
        "    lis=[]\n",
        "    for j in range(len(sentence[i])):\n",
        "      if len(sentence[i][j])>8 and sentence[i][j][7]== 'root':\n",
        "        chiffre = sentence[i][j][0]\n",
        "        for k in range(len(sentence[i])):\n",
        "          if len(sentence[i][k])>8 and sentence[i][k][6]== chiffre and 'nsubj'in sentence[i][k][7] and sentence[i][k][0] not in lis:\n",
        "            lis.append(sentence[i][k][0])\n",
        "            num += int(chiffre)-int(sentence[i][k][0])\n",
        "            deno+=1\n",
        "  return (num/deno)\n",
        "\n",
        "distance_tr = distance_verbe('RNN_UniversalDependencies_FR/Donnees/fr_sequoia-ud-train.conllu.txt')\n",
        "distance_te = distance_verbe('RNN_UniversalDependencies_FR/Donnees/fr_sequoia-ud-test.conllu.txt')\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uX0wIn3diiL",
        "colab_type": "code",
        "outputId": "19f72be9-1321-42b1-a819-1b9a3eca7336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "distance"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.569131832797428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}